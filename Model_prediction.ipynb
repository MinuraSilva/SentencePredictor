{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "# from sklearn.feature_selection import RFE, RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier#, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet, SGDClassifier, SGDRegressor\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bizzare problem: It seems that when you import one of lbgm, xgboost, Ridge, Lasso, ElasticNet, SGDClassifier, SGDRegressor, \n",
    "# if the below options are enabled, it will wreck any operation on a dataframe (including h df.head(), causing it to hang indefinitely\n",
    "\n",
    "# pd.options.display.max_rows = None  # to stop pandas from not displaying all columns because of screen width\n",
    "# pd.options.display.max_columns = None  # to stop pandas from not displaying all columns because of screen width\n",
    "# pd.options.display.max_colwidth = 100  # To prevent pandas from concatenating very long columns. Set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minur\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (8,9,12,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "sentencing_processed = pd.read_csv(\"Sentencing_processed_data.csv\",\n",
    "                                  parse_dates=[\"DISPOSITION_DATE\", \"SENTENCE_DATE\",\n",
    "                                                 \"INCIDENT_BEGIN_DATE\", \"INCIDENT_END_DATE\",\n",
    "                                                 \"ARREST_DATE\", \"ARRAIGNMENT_DATE\", \"RECEIVED_DATE\"],\n",
    "                                  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencing = sentencing_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each crime may have multiple charges, so must ensure that two cases from the same crime do not end up in different tain/test splits\n",
    "# because this will lead to data leaking to the test set.\n",
    "\n",
    "# Note that during cross validation, I ignore this because it is too much trouble to do the splits properly, so the train scores will likely be inflated\n",
    "# compared to the test scores, but since the test split is done correctly, the test score will be valid.\n",
    "\n",
    "# Technically, I shouldn't need to do this if my understanding of how sentencing works (each case gets an independent sentence),\n",
    "# but doing this to be on the safe side.\n",
    "\n",
    "# sentencing_sorted = sentencing.sort_values(by=[\"CASE_ID\"])\n",
    "# random.seed(a=123, version=2)  # for reproduceability\n",
    "# df_train = pd.DataFrame()\n",
    "# df_test = pd.DataFrame()\n",
    "# split_ratio = 0.2\n",
    "\n",
    "# # estimated to take exactly 1 hour on 233k examples\n",
    "# previous_id = 0\n",
    "# last_set = 0; # \"train\" or \"test\"\n",
    "\n",
    "# total_length = len(sentencing_sorted)\n",
    "\n",
    "# for i in range(len(sentencing_sorted)):\n",
    "#     if (i%100 == 0): print(i, time.time())\n",
    "#     curr_line = sentencing_sorted.iloc[i]\n",
    "#     if curr_line[\"CASE_ID\"] == previous_id:\n",
    "#         df_train.append(curr_line) if (last_set==\"train\") else df_test.append(curr_line)\n",
    "#     else:\n",
    "#         # sample random number to decide which dataset\n",
    "#         if (random.random() < split_ratio):\n",
    "#             last_set = \"train\"\n",
    "#             df_train.append(curr_line)\n",
    "#         else:\n",
    "#             last_set = \"test\"\n",
    "#             df_test.append(curr_line)\n",
    "            \n",
    "# print(\"Done split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time encoding for \"ARREST_DATE\"\n",
    "sentencing[\"month\"] = sentencing[\"ARREST_DATE\"].apply(lambda x: x.month)\n",
    "\n",
    "# sin/cos for seasonality\n",
    "sentencing[\"month_sin\"] = np.sin(2*np.pi*sentencing[\"month\"]/12)\n",
    "sentencing[\"month_cos\"] = np.cos(2*np.pi*sentencing[\"month\"]/12)\n",
    "\n",
    "# linear encoding\n",
    "min_date = min(sentencing[\"ARREST_DATE\"])\n",
    "sentencing[\"days_number\"] = (sentencing[\"ARREST_DATE\"] - min_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "df_train_1, df_test_1 = train_test_split(sentencing, test_size=0.2, random_state=123)\n",
    "print(len(df_test_1) / (len(df_test_1) + len(df_train_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184852"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_type = df_train_1[\"categorical_sentence\"]  # for categorical_sentence\n",
    "y_train_length = df_train_1[\"sentence_period_years\"]  # for sentence_period_years\n",
    "\n",
    "y_test_type = df_test_1[\"categorical_sentence\"]\n",
    "y_test_length = df_test_1[\"sentence_period_years\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize features for preprocessing\n",
    "\n",
    "# includes all features that are an outcome of the judicial process and not the crime except for any features\n",
    "# that are used to classify the crime (since I have no other way of knowing what the crime is). \n",
    "drop_features = [\"CASE_ID\", \"CASE_PARTICIPANT_ID\", \"CHARGE_ID\", \"CHARGE_VERSION_ID\", \"LENGTH_OF_CASE_in_Days\", \"SENTENCE_PHASE\",\n",
    "                \"SENTENCE_TYPE\", \"COMMITMENT_TYPE\", \"CURRENT_SENTENCE\", \"SENTENCE_JUDGE\",\n",
    "                \"CHARGE_DISPOSITION_REASON\", \"COURT_NAME\", \"COURT_FACILITY\", \"RECEIVED_DATE\",\n",
    "                \"DISPOSITION_DATE\", \"SENTENCE_DATE\", \"INCIDENT_BEGIN_DATE\", \"INCIDENT_END_DATE\", \"ARRAIGNMENT_DATE\",\n",
    "                \"ARREST_DATE\", \"month\"]\n",
    "# drop length of case since this is information from after sentencing\n",
    "# Drop sentence/commitment type since it has been merged into categorical_sentence\n",
    "# CHARGE_DISPOSITION_REASON - too many missing features\n",
    "# ARREST_DATE is dropped because we use the processed date features. month is a intermediary.\n",
    "\n",
    "numeric_features = [\"AGE_AT_INCIDENT\", \"month_sin\", \"month_cos\", \"days_number\", \"CHARGE_COUNT\"]\n",
    "\n",
    "# features to be one-hot encoded\n",
    "categorical_features = [\"OFFENSE_CATEGORY\", \"DISPOSITION_CHARGED_OFFENSE_TITLE\", \"CHARGE_DISPOSITION\",\n",
    "                        \"GENDER\", \"RACE\", \"UPDATED_OFFENSE_CATEGORY\",\n",
    "                        \"DISPOSITION_CHARGED_CHAPTER\", \"DISPOSITION_CHARGED_ACT\", \"DISPOSITION_CHARGED_SECTION\",\n",
    "                        \"DISPOSITION_CHARGED_CLASS\", \"INCIDENT_CITY\", \"LAW_ENFORCEMENT_AGENCY\", \"UNIT\",\n",
    "                        \"DISPOSITION_CHARGED_AOIC\", \"PRIMARY_CHARGE\"] #use one-hot encoding with drop first\n",
    "# UNIT is department of police force which is involved\n",
    "# AOIC refers to Administrative Office of the Illinois Courts ID\n",
    "# PRIMARY_CHARGE is boolean\n",
    "\n",
    "# ordinal encoding\n",
    "ordinal_features = []\n",
    "\n",
    "\n",
    "# what we are predicting (y)\n",
    "target_raw = [\"COMMITMENT_TERM\", \"COMMITMENT_UNIT\"] # raw target; will be dropped\n",
    "target_processed = [\"categorical_sentence\", \"sentence_period_years\"]\n",
    "\n",
    "drop_features = drop_features + target_raw + target_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a  = list(drop_features + numeric_features + categorical_features + ordinal_features)\n",
    "temp_a.sort()\n",
    "\n",
    "temp_b = list(sentencing.columns)\n",
    "temp_b.sort()\n",
    "\n",
    "assert (temp_a == temp_b), \"Columns do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minur\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Drop target columns - skip if running again\n",
    "# df_train = df_train.drop(columns=target_raw+target_processed, axis=1, errors='ignore')\n",
    "# df_test = df_test.drop(columns=target_raw+target_processed, axis=1, errors='ignore')\n",
    "\n",
    "df_train = df_train_1[numeric_features+categorical_features]\n",
    "df_test = df_test_1[numeric_features+categorical_features]\n",
    "\n",
    "\n",
    "df_train[numeric_features] = df_train[numeric_features].astype('float')  # ensure all numeric fields are float\n",
    "# df_train[\"PRIMARY_CHARGE\"] = df_train[\"PRIMARY_CHARGE\"].astype(str)  # convert boolean to string\n",
    "df_train[categorical_features] = df_train[categorical_features].astype(str)  # ensure no floats\n",
    "\n",
    "df_test[numeric_features] = df_test[numeric_features].astype('float')\n",
    "# df_test[\"PRIMARY_CHARGE\"] = df_test[\"PRIMARY_CHARGE\"].astype(str)\n",
    "df_test[categorical_features] = df_test[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The code above will lead to missing data for predicting the sentence duration as you should know what kind of sentence is given.\n",
    "# Ignoring for now, but this means that I should not predict duration without fixing this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do nothing estimator; https://scikit-learn.org/stable/developers/develop.html\n",
    "class Nothing(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, demo_param='demo'):\n",
    "        self.demo_param = demo_param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Do nothing\n",
    "        print()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Do nothing\n",
    "        return None\n",
    "\n",
    "    def transform(self, data):\n",
    "        # return data without doing anything\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "passthrough_transformer = Pipeline([\n",
    "    ('do_nothing', Nothing())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer_cat = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan, fill_value='?')),\n",
    "])\n",
    "\n",
    "categorical_transformer_ohe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan, fill_value='?')),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer_cat = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', missing_values=np.nan)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "numeric_transformer_ohe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', missing_values=np.nan)),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_cat = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer_cat, numeric_features),\n",
    "    ('categorical', categorical_transformer_cat, categorical_features)\n",
    "], remainder='drop')\n",
    "\n",
    "preprocessor_ohe = ColumnTransformer([\n",
    "    ('numeric', numeric_transformer_ohe, numeric_features),\n",
    "    ('categorical', categorical_transformer_ohe, categorical_features)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE_AT_INCIDENT                      2383\n",
       "month_sin                            3752\n",
       "month_cos                            3752\n",
       "days_number                          3752\n",
       "CHARGE_COUNT                            0\n",
       "OFFENSE_CATEGORY                        0\n",
       "DISPOSITION_CHARGED_OFFENSE_TITLE       0\n",
       "CHARGE_DISPOSITION                      0\n",
       "GENDER                                  0\n",
       "RACE                                    0\n",
       "UPDATED_OFFENSE_CATEGORY                0\n",
       "DISPOSITION_CHARGED_CHAPTER             0\n",
       "DISPOSITION_CHARGED_ACT                 0\n",
       "DISPOSITION_CHARGED_SECTION             0\n",
       "DISPOSITION_CHARGED_CLASS               0\n",
       "INCIDENT_CITY                           0\n",
       "LAW_ENFORCEMENT_AGENCY                  0\n",
       "UNIT                                    0\n",
       "DISPOSITION_CHARGED_AOIC                0\n",
       "PRIMARY_CHARGE                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('numeric',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='median',\n",
       "                                                                verbose=0)),\n",
       "                                                 ('scaler',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True))],\n",
       "                                          verbose=False),\n",
       "                                 ['...\n",
       "                                          verbose=False),\n",
       "                                 ['OFFENSE_CATEGORY',\n",
       "                                  'DISPOSITION_CHARGED_OFFENSE_TITLE',\n",
       "                                  'CHARGE_DISPOSITION', 'GENDER', 'RACE',\n",
       "                                  'UPDATED_OFFENSE_CATEGORY',\n",
       "                                  'DISPOSITION_CHARGED_CHAPTER',\n",
       "                                  'DISPOSITION_CHARGED_ACT',\n",
       "                                  'DISPOSITION_CHARGED_SECTION',\n",
       "                                  'DISPOSITION_CHARGED_CLASS', 'INCIDENT_CITY',\n",
       "                                  'LAW_ENFORCEMENT_AGENCY', 'UNIT',\n",
       "                                  'DISPOSITION_CHARGED_AOIC',\n",
       "                                  'PRIMARY_CHARGE'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_ohe.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('numeric',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='median',\n",
       "                                                                verbose=0)),\n",
       "                                                 ('scaler',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True))],\n",
       "                                          verbose=False),\n",
       "                                 ['...\n",
       "                                          verbose=False),\n",
       "                                 ['OFFENSE_CATEGORY',\n",
       "                                  'DISPOSITION_CHARGED_OFFENSE_TITLE',\n",
       "                                  'CHARGE_DISPOSITION', 'GENDER', 'RACE',\n",
       "                                  'UPDATED_OFFENSE_CATEGORY',\n",
       "                                  'DISPOSITION_CHARGED_CHAPTER',\n",
       "                                  'DISPOSITION_CHARGED_ACT',\n",
       "                                  'DISPOSITION_CHARGED_SECTION',\n",
       "                                  'DISPOSITION_CHARGED_CLASS', 'INCIDENT_CITY',\n",
       "                                  'LAW_ENFORCEMENT_AGENCY', 'UNIT',\n",
       "                                  'DISPOSITION_CHARGED_AOIC',\n",
       "                                  'PRIMARY_CHARGE'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_cat.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_cat.fit(df_train)\n",
    "preprocessor_ohe.fit(df_train)\n",
    "\n",
    "ohe = preprocessor_ohe.named_transformers_['categorical'].named_steps['onehot']\n",
    "ohe_feature_names = list(ohe.get_feature_names(categorical_features))\n",
    "\n",
    "new_columns_cat = numeric_features + categorical_features\n",
    "new_columns_ohe = numeric_features + ohe_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = pd.DataFrame(preprocessor_cat.transform(df_train), index=df_train.index, columns=new_columns_cat)\n",
    "X_test_cat  = pd.DataFrame(preprocessor_cat.transform(df_test), index=df_test.index,  columns=new_columns_cat)\n",
    "\n",
    "X_train_ohe = pd.DataFrame(preprocessor_ohe.transform(df_train), index=df_train.index, columns=new_columns_ohe)\n",
    "X_test_ohe  = pd.DataFrame(preprocessor_ohe.transform(df_test), index=df_test.index,  columns=new_columns_ohe)\n",
    "\n",
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "# replace any [, ], < in feature name since XGBoost has problems with it\n",
    "X_train_ohe.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_train_ohe.columns.values]\n",
    "X_test_ohe.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X_test_ohe.columns.values]\n",
    "# replace special characters since LightBGM has problems otherwise - this has problems with creating non unique features\n",
    "# X_train_ohe.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train_ohe.columns]\n",
    "# X_test_ohe.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test_ohe.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that I am not removing DISPOSITION_CHARGED_OFFENSE_TITLE and UPDATED_OFFENSE_CATEGORY, both of which are open to interpretation and therefore depend on the judgement to some extent.\n",
    "- Try dropping all but Primary charge (in case the non primary charges have the same sentence, which would be out of proportion for smaller charges grouped together with more serious charges.\n",
    "- Also leaving CHARGE_DISPOSITION. All cases in this dataset were convicted but the sentence might depend on whether the defendant plead guilty or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDC = DummyClassifier(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelXG = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLB = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCB = CatBoostClassifier(cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Time with n=100\n",
    "- LogisticRegression - 0.5s (1)\n",
    "- XGBoost - 10s (20)\n",
    "- CatBoost - 90s (180)\n",
    "\n",
    "\n",
    "- Logistic regression n=10000 - 80s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier\n",
      "8.31 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "\n",
      "LogisticRegression\n",
      "1min 21s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "n=10000\n",
    "\n",
    "print(\"DummyClassifier\")\n",
    "%timeit -n1 -r1 modelDC.fit(X_train_ohe.head(n), y_train_type.head(n))\n",
    "\n",
    "print(\"\\nLogisticRegression\")\n",
    "%timeit -n1 -r1 modelLR.fit(X_train_ohe.head(n), y_train_type.head(n))\n",
    "\n",
    "# print(\"\\nXGBoost\")\n",
    "# %timeit -n1 -r1 modelXG.fit(X_train_ohe.head(n), y_train_type.head(n))\n",
    "\n",
    "# print(\"\\nCatBoost\")\n",
    "# %timeit -n1 -r1 modelCB.fit(X_train_cat.head(n), y_train_type.head(n), verbose=1000)\n",
    "\n",
    "\n",
    "# Has problems with the feature names\n",
    "# print(\"\\nLightBGM\")\n",
    "# %timeit -n1 -r1 modelLB.fit(X_train_ohe.head(n), y_train_type.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier\n",
      "Train: 0.5736\n",
      "Test: 0.5771\n",
      "\n",
      "LogisticRegression\n",
      "Train: 0.7249\n",
      "Test: 0.6601\n"
     ]
    }
   ],
   "source": [
    "print(\"DummyClassifier\")\n",
    "print(f\"Train: {modelDC.score(X_train_ohe.head(n), y_train_type.head(n))}\")\n",
    "print(f\"Test: {modelDC.score(X_test_ohe.head(n), y_test_type.head(n))}\")\n",
    "\n",
    "print(\"\\nLogisticRegression\")\n",
    "print(f\"Train: {modelLR.score(X_train_ohe.head(n), y_train_type.head(n))}\")\n",
    "print(f\"Test: {modelLR.score(X_test_ohe.head(n), y_test_type.head(n))}\")\n",
    "\n",
    "# print(\"\\nXGBoost\")\n",
    "# print(f\"Train: {modelXG.score(X_train_ohe.head(n), y_train_type.head(n))}\")\n",
    "# print(f\"Test: {modelXG.score(X_test_ohe.head(n), y_test_type.head(n))}\")\n",
    "\n",
    "# print(\"\\nCatBoost\")\n",
    "# print(f\"Train: {modelCB.score(X_train_cat.head(n), y_train_type.head(n))}\")\n",
    "# print(f\"Test: {modelCB.score(X_test_cat.head(n), y_test_type.head(n))}\")\n",
    "\n",
    "\n",
    "# print(\"\\LightBGM\")\n",
    "# print(f\"Train: {modelLB.score(X_train_ohe.head(n), y_train_type.head(n))}\")\n",
    "# print(f\"Test: {modelLB.score(X_test_ohe.head(n), y_test_type.head(n))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DummyClassifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE_AT_INCIDENT                      object\n",
       "month_sin                            object\n",
       "month_cos                            object\n",
       "days_number                          object\n",
       "CHARGE_COUNT                         object\n",
       "OFFENSE_CATEGORY                     object\n",
       "DISPOSITION_CHARGED_OFFENSE_TITLE    object\n",
       "CHARGE_DISPOSITION                   object\n",
       "GENDER                               object\n",
       "RACE                                 object\n",
       "UPDATED_OFFENSE_CATEGORY             object\n",
       "DISPOSITION_CHARGED_CHAPTER          object\n",
       "DISPOSITION_CHARGED_ACT              object\n",
       "DISPOSITION_CHARGED_SECTION          object\n",
       "DISPOSITION_CHARGED_CLASS            object\n",
       "INCIDENT_CITY                        object\n",
       "LAW_ENFORCEMENT_AGENCY               object\n",
       "UNIT                                 object\n",
       "DISPOSITION_CHARGED_AOIC             object\n",
       "PRIMARY_CHARGE                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE_AT_INCIDENT</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>days_number</th>\n",
       "      <th>CHARGE_COUNT</th>\n",
       "      <th>OFFENSE_CATEGORY</th>\n",
       "      <th>DISPOSITION_CHARGED_OFFENSE_TITLE</th>\n",
       "      <th>CHARGE_DISPOSITION</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>RACE</th>\n",
       "      <th>UPDATED_OFFENSE_CATEGORY</th>\n",
       "      <th>DISPOSITION_CHARGED_CHAPTER</th>\n",
       "      <th>DISPOSITION_CHARGED_ACT</th>\n",
       "      <th>DISPOSITION_CHARGED_SECTION</th>\n",
       "      <th>DISPOSITION_CHARGED_CLASS</th>\n",
       "      <th>INCIDENT_CITY</th>\n",
       "      <th>LAW_ENFORCEMENT_AGENCY</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DISPOSITION_CHARGED_AOIC</th>\n",
       "      <th>PRIMARY_CHARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56210</th>\n",
       "      <td>0.489372</td>\n",
       "      <td>0.738924</td>\n",
       "      <td>1.2862</td>\n",
       "      <td>-0.75152</td>\n",
       "      <td>-0.252813</td>\n",
       "      <td>Narcotics</td>\n",
       "      <td>POSSESSION OF A CONTROLLED SUBSTANCE</td>\n",
       "      <td>Plea Of Guilty</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Narcotics</td>\n",
       "      <td>720</td>\n",
       "      <td>570</td>\n",
       "      <td>402(c)</td>\n",
       "      <td>4</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>CHICAGO PD</td>\n",
       "      <td>District 10 - Ogden</td>\n",
       "      <td>5101110</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AGE_AT_INCIDENT month_sin month_cos days_number CHARGE_COUNT  \\\n",
       "56210        0.489372  0.738924    1.2862    -0.75152    -0.252813   \n",
       "\n",
       "      OFFENSE_CATEGORY     DISPOSITION_CHARGED_OFFENSE_TITLE  \\\n",
       "56210        Narcotics  POSSESSION OF A CONTROLLED SUBSTANCE   \n",
       "\n",
       "      CHARGE_DISPOSITION GENDER   RACE UPDATED_OFFENSE_CATEGORY  \\\n",
       "56210     Plea Of Guilty   Male  Black                Narcotics   \n",
       "\n",
       "      DISPOSITION_CHARGED_CHAPTER DISPOSITION_CHARGED_ACT  \\\n",
       "56210                         720                     570   \n",
       "\n",
       "      DISPOSITION_CHARGED_SECTION DISPOSITION_CHARGED_CLASS INCIDENT_CITY  \\\n",
       "56210                      402(c)                         4       Chicago   \n",
       "\n",
       "      LAW_ENFORCEMENT_AGENCY                 UNIT DISPOSITION_CHARGED_AOIC  \\\n",
       "56210             CHICAGO PD  District 10 - Ogden                  5101110   \n",
       "\n",
       "      PRIMARY_CHARGE  \n",
       "56210           True  "
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.07036\n",
      "0:\tlearn: 1.5486981\ttotal: 70.5ms\tremaining: 1m 10s\n",
      "100:\tlearn: 0.4962509\ttotal: 6.51s\tremaining: 58s\n",
      "200:\tlearn: 0.2588810\ttotal: 15s\tremaining: 59.7s\n",
      "300:\tlearn: 0.1577205\ttotal: 23.6s\tremaining: 54.8s\n",
      "400:\tlearn: 0.1078402\ttotal: 32.2s\tremaining: 48.1s\n",
      "500:\tlearn: 0.0821076\ttotal: 40.8s\tremaining: 40.6s\n",
      "600:\tlearn: 0.0647056\ttotal: 49.7s\tremaining: 33s\n",
      "700:\tlearn: 0.0533171\ttotal: 58.6s\tremaining: 25s\n",
      "800:\tlearn: 0.0451912\ttotal: 1m 8s\tremaining: 17s\n",
      "900:\tlearn: 0.0388740\ttotal: 1m 17s\tremaining: 8.54s\n",
      "999:\tlearn: 0.0344301\ttotal: 1m 26s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1cf31d5c128>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
